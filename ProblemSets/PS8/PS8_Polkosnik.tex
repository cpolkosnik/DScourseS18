\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\title{PS8}
\author{Conrad Polkosnik }
\date{March 27,2018}


\begin{document}
\maketitle

\section{Part 5}
The estimates are nearly the exact same.

\section{Part 7}
All values end up being nearly the exact same

\section{Part 9}
The estimates are nearly the exact same as the true beta values. I have learned that the lm() function in R is extremely powerful. After disecting through doing OLS regression the long way, I realize how great the lm() function in R really is. The table on the next page shows the estimates of beta which are nearly the exact same as the true values, confirming that the function estimates parameters extremely well.

\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\begin{tabular}{@{\extracolsep{5pt}}lc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
 & \multicolumn{1}{c}{\textit{Dependent variable:}} \\
\cline{2-2}
\\[-1.8ex] & y \\
\hline \\[-1.8ex]
 X1 & 1.501$^{***}$ \\
  & (0.002) \\
  & \\
 X2 & $-$0.996$^{***}$ \\
  & (0.002) \\
  & \\
 X3 & 0.251$^{***}$ \\
  & (0.002) \\
  & \\
 X4 & 0.747$^{***}$ \\
  & (0.002) \\
  & \\
 X5 & 3.502$^{***}$ \\
  & (0.002) \\
  & \\
 X6 & $-$1.999$^{***}$ \\
  & (0.002) \\
  & \\
 X7 & 0.501$^{***}$ \\
  & (0.002) \\
  & \\
 X8 & 0.999$^{***}$ \\
  & (0.002) \\
  & \\
 X9 & 1.253$^{***}$ \\
  & (0.002) \\
  & \\
 X10 & 1.999$^{***}$ \\
  & (0.002) \\
  & \\
\hline \\[-1.8ex]
Observations & 100,000 \\
R$^{2}$ & 0.991 \\
Adjusted R$^{2}$ & 0.991 \\
Residual Std. Error & 0.500 (df = 99990) \\
F Statistic & 1,080,206.000$^{***}$ (df = 10; 99990) \\
\hline
\hline \\[-1.8ex]
\textit{Note:}  & \multicolumn{1}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\
\end{tabular}
\end{table}

\end{document}{}
